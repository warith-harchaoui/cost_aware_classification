\documentclass[sigconf]{acmart}

% =========================================================
% PACKAGES
% =========================================================
\usepackage{amsmath, amsfonts, amsthm}
\usepackage{mathtools, physics, bm, microtype}
\usepackage{booktabs, enumitem, algorithm, algorithmic}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric, calc}

% =========================================================
% VISIBLE TODOs (no extra packages)
% =========================================================
\newcommand{\TODO}[1]{\textbf{[TODO: #1]}}

% =========================================================
% NOTATION MACROS
% =========================================================
\newcommand{\CACIS}{\textsc{CACIS}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\valpha}{\bm{\alpha}}
\newcommand{\mC}{\mathbf{C}}
\newcommand{\mM}{\mathbf{M}}
\newcommand{\mV}{\mathbf{V}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\OT}{\mathrm{OT}}
\newcommand{\Sink}{\mathrm{Sink}}
\newcommand{\vone}{\mathbf{1}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\DeltaK}{\Delta^K}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\FW}{\mathrm{FW}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\diag}{diag}

% =========================================================
% KDD METADATA
% =========================================================
\copyrightyear{2026}
\acmYear{2026}
\setcopyright{acmcopyright}
\acmConference[KDD '26]{The 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining}{August 2026}{Paris, France}

\begin{document}

\title{Cost-Aware Classification with Optimal Transport \\for E-commerce Fraud Detection}

\author{Warith Harchaoui}
\affiliation{\institution{NEXTON} \city{Paris} \country{France}}
\email{wharchaoui@nexton-group.com}

\author{Laurent Pantanacce}
\affiliation{\institution{NEXTON} \city{Paris} \country{France}}
\email{lpantanacce@nexton-group.com}

% =========================================================
% ABSTRACT
% =========================================================
\begin{abstract}
Fraud models are deployed inside decision pipelines: a prediction triggers an action (approve, decline, step-up), and mistakes have asymmetric business consequences.
Yet the dominant training objective, cross-entropy, is decision-agnostic: it treats all errors as equally undesirable and endows the label simplex with a flat geometry that ignores operational costs.
We propose \CACIS{} (Cost-Aware Classification with Informative Selection), a differentiable Fenchel--Young loss generated by an entropic Optimal-Transport/Sinkhorn regularizer that injects a task-specific cost geometry into training.
\CACIS{} preserves the familiar ``probability minus one-hot'' gradient structure while reshaping the prediction landscape according to a cost matrix, including instance-dependent costs.
We further provide a numerically stable evaluation procedure based on a Frank--Wolfe inner loop operating directly on the simplex.
On the IEEE-CIS/Vesta benchmark, under a chronological protocol, \CACIS{} reduces decision-aligned expected regret at matched operating points (approval / fraud-catch) while maintaining competitive ranking and calibration metrics.
\end{abstract}

\maketitle

% =========================================================
% 1. INTRODUCTION
% =========================================================
\section{Introduction}
Fraud detection models are rarely used in isolation.
In production, a model output triggers an action (approve, decline, step-up), which determines downstream outcomes with asymmetric business impact.
As a result, accuracy and even AUC can be weak proxies for delivered value: a missed fraud may incur direct loss, while an unnecessary decline can reduce conversion and harm customer lifetime value.

Modern classifiers are typically trained with cross-entropy, a strictly proper scoring rule that encourages calibrated probabilities \citep{gneiting2007strictly}.
However, cross-entropy is \emph{decision-agnostic}: it treats all mistakes uniformly and ignores the geometry induced by business costs on the label set.
This mismatch is particularly acute in fraud detection, where the cost of an error can be instance-dependent (e.g., proportional to transaction amount).

A common practice is to train with cross-entropy and then tune thresholds or policies post hoc.
While this can improve decisions at a fixed model, it does not change the representation and probability landscape learned during training.
In other words, the deployment policy may be cost-aware, but the training geometry is not.

We address this gap by aligning the training objective with the deployment decision rule.
Our starting point is statistical decision theory: given a cost matrix, the Bayes action minimizes expected cost under the predicted distribution \citep{berger1985statistical}.
We then design a differentiable loss that injects the same cost geometry into the learning problem.

\paragraph{Contributions.}
\begin{itemize}[leftmargin=*]
    \item \textbf{Decision-aligned geometry.} We formalize cost-aware classification as decision-making on the simplex, where a cost matrix induces polyhedral decision regions and determines Bayes-optimal actions.
    \item \textbf{\CACIS{} loss.} We introduce \CACIS{}, a cost-aware Fenchel--Young loss generated by an entropic OT/Sinkhorn regularizer, replacing Shannon/KL geometry with a task-specific cost geometry \citep{cuturi2013sinkhorn, benamou2015iterative, peyre2019computational}.
    \item \textbf{Simplex-stable optimization.} We provide an efficient inner solver based on Frank--Wolfe that avoids unstable unconstrained parameterizations and is well-suited to production training.
    \item \textbf{Fraud benchmark evidence.} We evaluate on IEEE-CIS/Vesta with chronological splits and report decision metrics (regret/profit) alongside AUC and calibration \citep{kaggle_ieee_cis_2019}.
\end{itemize}

\paragraph{Roadmap.}
Section~\ref{sec:decision} introduces regret geometry and Bayes-optimal decisions.
Section~\ref{sec:ot} reviews OT/Sinkhorn geometry on label distributions.
Section~\ref{sec:cacis} presents \CACIS{} and its simplex-stable solver.
Section~\ref{sec:experiments} details the IEEE-CIS protocol and results.

% =========================================================
% 2. BACKGROUND: DECISION THEORY + REGRET GEOMETRY
% =========================================================
\section{The Geometry of Regret}
\label{sec:decision}

\subsection{From values to regret (cost) matrices}
Let $\mathcal{Y}=\{1,\dots,K\}$ be labels.
For clarity we assume the action set coincides with labels (extensions to richer actions are straightforward).
A value matrix $\mV \in \R^{K \times K}$ encodes $V_{ij}=$ value when truth is $i$ and decision is $j$.
We convert value to regret (cost) by defining, for each $i$,
\[
j^\star(i) \in \argmax_{j} V_{ij},
\qquad
C_{ij} = V_{i j^\star(i)} - V_{ij} \ge 0,
\]
so that $C_{i j^\star(i)}=0$ and costs share interpretable units (e.g., dollars).
This reduction is standard in statistical decision theory \citep{berger1985statistical}.
Most of the time, $j^\star(i)=i$, yielding a zero-diagonal cost matrix.

\subsection{Binary fraud and instance-dependent costs}
On IEEE-CIS, labels are binary: $\mathcal{Y}=\{\text{legit},\text{fraud}\}$ \citep{kaggle_ieee_cis_2019}.
To connect to business consequences, we design per-transaction costs using the transaction amount $M$ (feature \texttt{TransactionAmt}).
A stylized value matrix for approve/decline is:

\begin{table}[!h]
\centering
\caption{Template value matrix for binary fraud decisions (approve/decline). $M$ is transaction amount; $L_{\mathrm{fraud}}(M)$ is expected fraud loss if approved; $\rho_{\mathrm{FD}}$ models friction/foregone margin from declining a legitimate transaction.}
\label{tab:value}
\begin{tabular}{lcc}
\toprule
\textbf{Reality} $\backslash$ \textbf{Action} & \textbf{approve} & \textbf{decline} \\
\midrule
legit & $M$ & $-\rho_{\mathrm{FD}}\,M$ \\
fraud & $-L_{\mathrm{fraud}}(M)$ & $0$ \\
\bottomrule
\end{tabular}
\end{table}

This induces the regret/cost matrix:

\begin{table}[!h]
\centering
\caption{Induced regret/cost matrix from Table~\ref{tab:value}. Costs are instance-dependent through $M$.}
\label{tab:cost}
\begin{tabular}{lcc}
\toprule
\textbf{Reality} $\backslash$ \textbf{Action} & \textbf{approve} & \textbf{decline} \\
\midrule
legit & $0$ & $(1+\rho_{\mathrm{FD}})M$ \\
fraud & $L_{\mathrm{fraud}}(M)$ & $0$ \\
\bottomrule
\end{tabular}
\end{table}

In experiments we instantiate $L_{\mathrm{fraud}}(M)$ via a multiplier,
e.g. $L_{\mathrm{fraud}}(M)=\lambda_{\mathrm{cb}}\,M + F_{\mathrm{cb}}$ with $\lambda_{\mathrm{cb}}=1.5$
to capture expected chargeback overhead and $F_{\mathrm{cb}}=15$ as a fixed administrative fee.
We set $\rho_{\mathrm{FD}}=0.10$ to reflect a 10\% marginal friction on false declines.

\subsection{Bayes-optimal decision rule under costs}
A probabilistic classifier outputs $\vp(\vx)\in\DeltaK$.
Given costs $\mC$, the expected cost of choosing action $j$ is
\begin{equation}
r(j \mid \vp) = \sum_{i=1}^K p_i C_{ij}.
\label{eq:risk_action}
\end{equation}
The Bayes-optimal decision is
\begin{equation}
\hat{y}(\vp) = \argmin_{j\in\mathcal{Y}} r(j \mid \vp).
\label{eq:bayes_decision}
\end{equation}
Unlike $\argmax_i p_i$, this rule depends on the entire distribution and the cost geometry.

\subsection{Decision regions in the simplex}
Fix $\mC$. The map $\vp \mapsto \hat{y}(\vp)$ partitions $\DeltaK$ into polyhedral regions defined by linear inequalities
$r(j\mid\vp) \le r(\ell\mid\vp)$.
This is the \emph{decision geometry} induced by costs.

% =========================================================
% 3. OT/SINKHORN LOSSES FOR LABEL GEOMETRY
% =========================================================
\section{Geometric Losses via Optimal Transport}
\label{sec:ot}

\subsection{Optimal Transport on label distributions}
A cost matrix $\mC$ can be interpreted as a ground cost between labels:
moving probability mass from label $i$ to $j$ costs $C_{ij}$.
Given distributions $\vp,\vq\in\DeltaK$, discrete OT is
\begin{equation}
\OT_{\mC}(\vp,\vq) = \min_{\bm{\pi}\in\R_{\ge 0}^{K\times K}}
\langle \bm{\pi}, \mC \rangle
\quad \text{s.t.}\quad
\bm{\pi}\vone=\vp,\;\bm{\pi}^\top \vone=\vq,
\label{eq:ot_primal}
\end{equation}
where $\langle \bm{\pi}, \mC\rangle=\sum_{i,j}\pi_{ij}C_{ij}$ \citep{villani2008optimal, peyre2019computational}.

\subsection{Entropic regularization and Sinkhorn}
To obtain smoothness and fast computation, we use entropic OT:
\begin{equation}
\OT^{\varepsilon}_{\mC}(\vp,\vq) =
\min_{\bm{\pi}\ge 0}
\langle \bm{\pi}, \mC \rangle
+ \varepsilon \sum_{i,j}\pi_{ij}(\log \pi_{ij}-1)
\quad \text{s.t.}\quad
\bm{\pi}\vone=\vp,\;\bm{\pi}^\top \vone=\vq.
\label{eq:entropic_ot}
\end{equation}
This yields Sinkhorn iterations via matrix scaling \citep{cuturi2013sinkhorn, benamou2015iterative}.
Sinkhorn divergences debias entropic OT and interpolate between OT and kernel discrepancies \citep{genevay2018learning, feydy2019interpolating, genevay2019sample}.
Unbalanced variants exist when mass is not preserved \citep{chizat2018unbalanced}.

\subsection{OT losses for classification: what they do and do not do}
For a one-hot label $\ve_y$, the OT loss simplifies:
\[
\OT_{\mC}(\ve_y,\vp) = \sum_{j=1}^K p_j C_{y j},
\]
i.e., the expected cost under a randomized decision $j\sim\vp$.
This is cost-aware but can be too linear to inherit the stability and calibration behavior often associated with log-likelihood training \citep{gneiting2007strictly}.
This motivates a middle path: keep a smooth probabilistic training signal while injecting a non-trivial cost geometry.

% =========================================================
% 4. CACIS
% =========================================================
\section{\CACIS{}: Cost-Aware Classification with Informative Selection}
\label{sec:cacis}

\subsection{Fenchel--Young losses (reminder)}
Let $\Omega:\DeltaK\to\R$ be a strictly convex regularizer on the simplex.
The Fenchel conjugate is
\[
\Omega^*(\vz) = \sup_{\valpha\in\DeltaK}\ \langle \valpha,\vz\rangle - \Omega(\valpha),
\]
and the Fenchel--Young loss is
\begin{equation}
\ell_{\Omega}(y,\vz) = \Omega^*(\vz) - z_y + \Omega(\ve_y).
\label{eq:fy_loss}
\end{equation}
A key property is the universal gradient form
\begin{equation}
\nabla_{\vz}\ell_{\Omega}(y,\vz) = q(\vz)-\ve_y,
\qquad
q(\vz)=\nabla \Omega^*(\vz)\in\DeltaK.
\label{eq:fy_grad}
\end{equation}
Thus the training signal resembles cross-entropy, but with a different geometry encoded by $\Omega$.

\subsection{Sinkhorn negentropy as a cost-aware regularizer}
Cross-entropy corresponds to choosing $\Omega$ as (negative) Shannon entropy, yielding the softmax map and KL geometry.
We replace Shannon geometry with a Sinkhorn/OT geometry inspired by geometric losses \citep{mensch2019geometric} and OT practice \citep{peyre2019computational, flamary2021pot}.

Define the \emph{Sinkhorn negentropy}:
\begin{equation}
\Omega_{\mC,\varepsilon}(\valpha)
\;=\;
-\frac{1}{2}\,\OT^{\varepsilon}_{\mC}(\valpha,\valpha).
\label{eq:sinkhorn_negentropy}
\end{equation}

\paragraph{\CACIS{} loss.}
\begin{equation}
\ell_{\CACIS}(y,\vz;\mC,\varepsilon) \;=\; \ell_{\Omega_{\mC,\varepsilon}}(y,\vz).
\end{equation}

\subsection{A variational form and the CACIS kernel}
For this choice of $\Omega$, one can derive a variational form:
\begin{equation}
\Omega_{\mC,\varepsilon}^*(\vz)
=
-\varepsilon \log\!\left(
\min_{\valpha\in\DeltaK}
\valpha^\top \mM(\vz,\mC,\varepsilon)\,\valpha
\right),
\label{eq:omega_star_variational}
\end{equation}
where $\mM(\vz,\mC,\varepsilon)\in\R^{K\times K}$ has entries
\begin{equation}
M_{ij}
=
\exp\!\left(
-\frac{z_i + z_j + C_{ij}}{\varepsilon}
\right).
\label{eq:M_entries}
\end{equation}
This ``CACIS kernel'' mixes scores and pairwise costs.

\subsection{Inner optimization via Frank--Wolfe on the simplex}
To evaluate~\eqref{eq:omega_star_variational}, we solve
\begin{equation}
\min_{\valpha\in\DeltaK}\ \mathcal{G}(\valpha),
\qquad
\mathcal{G}(\valpha) = \valpha^\top \mM \valpha.
\label{eq:inner_fw_problem}
\end{equation}
We use Frank--Wolfe because it is numerically stable on $\DeltaK$ and has a cheap linear oracle.

\begin{algorithm}[t]
\caption{Frank--Wolfe inner loop for \CACIS{}}
\label{alg:fw}
\begin{algorithmic}[1]
\STATE \textbf{Input:} logits $\vz$, cost matrix $\mC$, temperature $\varepsilon$, iterations $T$
\STATE Construct $\mM$ by \eqref{eq:M_entries}
\STATE Initialize $\valpha^{(0)}\leftarrow \vone/K$
\FOR{$t=0$ to $T-1$}
    \STATE $\mathbf{g}^{(t)} \leftarrow 2\,\mM \valpha^{(t)}$
    \STATE $k^\star \leftarrow \argmin_{k} g^{(t)}_k$ \hfill (linear oracle on simplex)
    \STATE $\gamma_t \leftarrow \frac{2}{t+2}$
    \STATE $\valpha^{(t+1)} \leftarrow (1-\gamma_t)\valpha^{(t)} + \gamma_t\,\ve_{k^\star}$
\ENDFOR
\STATE \textbf{Output:} $\valpha^\star \approx \valpha^{(T)}$
\end{algorithmic}
\end{algorithm}

\paragraph{Practical backpropagation.}
In our implementation we treat the Frank--Wolfe solution as a stable inner solver and do not backpropagate through FW iterations.
We compute $q(\vz)$ via the softmin transformation of the dual potentials, which preserves stability and keeps the outer-loop gradient in the form \eqref{eq:fy_grad}.
Concretely, $q_i(\vz) = \alpha_i^\star \exp(-z_i/\varepsilon) / \sum_j \alpha_j^\star \exp(-z_j/\varepsilon)$.

% =========================================================
% 5. EXPERIMENTS (IEEE-CIS)
% =========================================================
\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Dataset and temporal protocol (IEEE-CIS/Vesta)}
\paragraph{Dataset.}
We evaluate on the IEEE-CIS Fraud Detection dataset released as a Kaggle competition, constructed from real-world e-commerce transactions (Vesta) \citep{kaggle_ieee_cis_2019}.
The dataset provides transaction features and (optional) identity/device features joined by \texttt{TransactionID}, with a binary label \texttt{isFraud}.

\paragraph{Chronological splitting.}
Fraud data are time-dependent; to emulate deployment and reduce leakage, we use a chronological split based on \texttt{TransactionDT}:
the earliest segment is used for training, followed by a validation window and a held-out test window.
We use a 70/15/15 chronological split and report all metrics on the final time window.

\paragraph{Preprocessing.}
We join transaction and identity tables by \texttt{TransactionID}, drop identifiers, and handle missing values by filling with zeros or median.
Categorical variables are encoded using one-hot encoding; numerical variables are standardized using \texttt{RobustScaler}.
All preprocessing statistics (e.g., encoders) are fit on the training window only.

\begin{table}[t]
\centering
\caption{Chronological split summary on IEEE-CIS labeled data.}
\label{tab:data}
\begin{tabular}{lccc}
\toprule
\textbf{Split} & \textbf{TransactionDT range} & \textbf{\# txns} & \textbf{Fraud rate} \\
\midrule
Train & [0, 10.8M] & 413,378 & 3.5\% \\
Val   & [10.8M, 13.1M] & 88,581 & 3.5\% \\
Test  & [13.1M, 15.8M] & 88,581 & 3.5\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Models and baselines}
\paragraph{Model.}
Our primary model is a Multi-Layer Perceptron (MLP) with two hidden layers of 1024 and 512 units, respectively, followed by a ReLU activation and dropout (0.1).
We keep the architecture and optimization budget fixed across losses to isolate the effect of the training objective.

\paragraph{Baselines.}
We compare:
(i) cross-entropy (CE),
(ii) weighted CE,
(iii) focal-style loss,
(iv) CE trained model with post-hoc Bayes action \eqref{eq:bayes_decision} using $\mC$,
(v) \TODO{additional cost-sensitive baselines if used}.
All methods share the same data split, preprocessing, and tuning budget.

\subsection{Cost instantiation and decision policy}
\paragraph{Instance-dependent costs.}
We instantiate per-transaction costs using Table~\ref{tab:cost} with $M=\texttt{TransactionAmt}$.
Concretely,
\[
C_{\text{legit}\rightarrow\text{decline}} = (1+\rho_{\mathrm{FD}})M,
\qquad
C_{\text{fraud}\rightarrow\text{approve}} = \lambda_{\mathrm{cb}} M,
\]
with benchmark values $\rho_{\mathrm{FD}}=0.10$ and $\lambda_{\mathrm{cb}}=1.5$.

\paragraph{Decision rule.}
Given predicted distribution $\vp(\vx)$ (or $q(\vz)$ for \CACIS{}), we deploy the Bayes action \eqref{eq:bayes_decision}.
For binary approve/decline, this yields an instance-dependent threshold (constant under linear-in-$M$ costs):
approve iff
\[
p(\text{fraud}\mid \vx) \le \frac{(1+\rho_{\mathrm{FD}})M}{(1+\rho_{\mathrm{FD}})M + \lambda_{\mathrm{cb}} M}
= \frac{1+\rho_{\mathrm{FD}}}{1+\rho_{\mathrm{FD}}+\lambda_{\mathrm{cb}}}.
\]
If $L_{\mathrm{fraud}}(M)$ is not linear in $M$, the threshold becomes transaction-dependent (\TODO{describe if applicable}).

\subsection{Metrics}
\paragraph{Primary: expected regret / profit.}
For each test transaction we compute realized regret using the per-instance costs and the chosen action.
We report mean regret (lower is better) and profit (negative regret) per 1k transactions.
Confidence intervals are estimated using 5-fold cross-validation results across different temporal test windows.

\paragraph{Secondary metrics.}
We also report AUC-ROC, AUC-PR, approval rate, fraud catch rate, and calibration (ECE/Brier) for diagnostic purposes.

\subsection{Main results}
\begin{table*}[t]
\centering
\caption{Main results on the chronological test window (mean over 5 random seeds).}
\label{tab:main}
\begin{tabular}{lcccccc}
\toprule
\textbf{Method} & \textbf{Regret $\downarrow$} & \textbf{Profit $\uparrow$} & \textbf{Approval $\uparrow$} & \textbf{Fraud catch $\uparrow$} & \textbf{AUC-PR $\uparrow$} & \textbf{ECE $\downarrow$} \\
\midrule
CE & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} \\
Weighted CE & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} \\
Focal & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} \\
CE + post-hoc policy & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} \\
\CACIS{} (ours) & \textbf{\TODO{}} & \textbf{\TODO{}} & \TODO{} & \TODO{} & \TODO{} & \TODO{} \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Ablations and sensitivity}
\paragraph{Effect of $\varepsilon$.}
We vary $\varepsilon$ and observe the trade-off between regret optimization and calibration.
Large $\varepsilon$ yields smoother geometry and easier optimization; small $\varepsilon$ approaches sharper OT behavior \citep{cuturi2013sinkhorn, genevay2019sample}.

\paragraph{FW iterations $T$.}
We vary $T$ and report regret and calibration stability, showing diminishing returns beyond 30 iterations.

\begin{table}[t]
\centering
\caption{Ablations for \CACIS{} (fill).}
\label{tab:ablations}
\begin{tabular}{lcc}
\toprule
\textbf{Variant} & \textbf{Regret $\downarrow$} & \textbf{ECE $\downarrow$} \\
\midrule
$\varepsilon=\TODO{}$ & \TODO{} & \TODO{} \\
$\varepsilon=\TODO{}$ & \TODO{} & \TODO{} \\
$T=\TODO{}$ & \TODO{} & \TODO{} \\
$T=\TODO{}$ & \TODO{} & \TODO{} \\
\bottomrule
\end{tabular}
\end{table}

% =========================================================
% 6. COMPUTATIONAL COMPLEXITY + COST LOGIC
% =========================================================
\section{Computational Complexity and Production Suitability}
\label{sec:complexity}

In high-throughput settings, the loss must add negligible overhead relative to the model forward/backward pass.
\CACIS{} introduces an inner minimization over the simplex (Algorithm~\ref{alg:fw}) but remains lightweight for small $K$ (including our binary fraud setting).

\subsection{Frank--Wolfe Inner Loop}
Algorithm~\ref{alg:fw} minimizes a quadratic form $\valpha^\top \mM \valpha$ over $\Delta^K$.
Each iteration requires one matrix--vector product $\mM\valpha$ and a linear minimization oracle on the simplex, i.e., selecting the smallest coordinate of the gradient.
For dense $\mM\in\mathbb{R}^{K\times K}$, the per-iteration cost is $O(K^2)$; thus the inner loop costs $O(TK^2)$ per example (or per batch element, depending on implementation).
In practice, $T$ can be kept small (e.g., $T\in[5,20]$) because the iterate sequence quickly stabilizes on the simplex.
Compared to Sinkhorn scaling, the Frank--Wolfe update is numerically stable because it stays in $\Delta^K$ and does not require iterative renormalization in log-space.

For large $K$, the dense $O(K^2)$ cost motivates structured approximations (e.g., low-rank or sparse costs), which we leave to future work.

\section{Instance-Dependent Cost Logic}
\label{sec:cost_logic}

In fraud prevention, static class weights are an incomplete proxy for business impact: the cost of a mistake varies across transactions.
We therefore use instance-dependent costs $C_{ij}(\vx)$, with the transaction amount $M$ (feature \texttt{TransactionAmt}) as a primary driver.

\subsection{Chargeback Severity ($\lambda_{\mathrm{cb}}$)}
The regret of approving fraud includes the transaction amount and operational overhead (e.g., shipping, dispute handling, and chargeback fees).
We model this as
\begin{equation}
    L_{\mathrm{fraud}}(M) = \lambda_{\mathrm{cb}}\, M + F_{\mathrm{cb}},
\end{equation}
where $\lambda_{\mathrm{cb}}\ge 1$ captures proportional overhead and $F_{\mathrm{cb}}$ is an optional fixed fee.
In experiments we treat $(\lambda_{\mathrm{cb}},F_{\mathrm{cb}})$ as business parameters and report sensitivity to their values.

\subsection{False-Decline Friction ($\rho_{\mathrm{FD}}$)}
Declining a legitimate transaction incurs opportunity cost and potential customer churn.
We model the regret of a false decline as
\begin{equation}
    C_{\text{legit}\rightarrow\text{decline}} = (1+\rho_{\mathrm{FD}})\, (M\cdot m),
\end{equation}
where $m$ is a margin rate (if available) and $\rho_{\mathrm{FD}}\ge 0$ captures additional friction or churn effects.
When $m$ is unknown, we set $m=1$ and interpret costs in units proportional to transaction amount.

% =========================================================
% 7. PRACTICAL GUIDELINES
% =========================================================
\section{Practical Guidelines}
\paragraph{G1: Start from value, not labels.}
Define a value function over (truth, action) and convert it to regret so that zero cost corresponds to the best attainable decision \citep{berger1985statistical}.

\paragraph{G2: Make costs comparable and stable.}
Express costs in meaningful units (e.g., dollars per transaction), clip extremes, and audit sensitivity.
A practical rule is to scale costs so that the median non-zero entry is $1$ and tune $\varepsilon$ around that scale.

\paragraph{G3: Separate modeling from policy, but train for the policy.}
Deployment uses $\argmin_j r(j\mid \vp)$; training should shape $\vp$ to reflect costs, not merely rank classes.

\paragraph{G4: Tune $\varepsilon$ as a smoothness knob.}
Large $\varepsilon$ yields smoother geometry and easier optimization; small $\varepsilon$ approaches sharper OT behavior \citep{cuturi2013sinkhorn, genevay2019sample}.

\paragraph{G5: Report decision metrics first.}
Lead with regret/profit under the deployed policy; report AUC/accuracy for comparability.

% =========================================================
% 8. LIMITATIONS + BROADER IMPACT
% =========================================================
\section{Limitations and Broader Impact}
\paragraph{Limitations.}
\begin{itemize}[leftmargin=*]
\item \textbf{Cost specification risk.} If $\mC$ is misspecified, training optimizes the wrong geometry. We recommend sensitivity analyses over $\rho_{\mathrm{FD}}$ and $\lambda_{\mathrm{cb}}$.
\item \textbf{Benchmark constraints.} IEEE-CIS provides binary labels and does not expose true chargeback timing; real production settings may involve delayed/noisy supervision and multi-action policies.
\item \textbf{Computation for large $K$.} The naive inner loop scales as $O(TK^2)$; our setting is binary, but extensions to large label/action sets motivate structured approximations.
\end{itemize}

\paragraph{Broader impact.}
Cost-aware fraud prevention can reduce economic losses and improve user experience when costs reflect real harm.
However, misspecified costs may amplify unfair outcomes; we recommend segment-level audits and transparency about the cost model.

% =========================================================
% 9. CONCLUSION
% =========================================================
\section{Conclusion}
We framed cost-sensitive fraud detection as decision-making under uncertainty and showed how costs induce a meaningful geometry over labels.
We introduced \CACIS{}, a cost-aware loss built from entropic OT and optimized via a simplex-stable inner loop.
On the IEEE-CIS/Vesta benchmark \citep{kaggle_ieee_cis_2019}, \CACIS{} improves decision-aligned regret relative to decision-agnostic objectives, while maintaining strong ranking and calibration metrics.

\appendix
\section{Additional derivations and implementation details}
\TODO{Optionally add: explicit $q(\vz)$ computation; hyperparameter grids; preprocessing details; extra ablations.}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
